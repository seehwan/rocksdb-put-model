#!/usr/bin/env python3
"""
ì¢…í•©ì  v5 ëª¨ë¸ ë°ì´í„° ê²€ì¦
ì‹¤ì œ ì‹¤í—˜ ë°ì´í„°ì™€ ëª¨ë¸ ì˜ˆì¸¡ê°’ ë¹„êµ ë¶„ì„
"""

import json
import numpy as np
import pandas as pd
from datetime import datetime
import os

def load_experimental_data():
    """ì‹¤í—˜ ë°ì´í„° ë¡œë“œ"""
    print("=== ì‹¤í—˜ ë°ì´í„° ë¡œë“œ ===")
    print(f"ë¡œë“œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # ì‹¤í—˜ ë°ì´í„° (09-09 ì‹¤í—˜ ê¸°ì¤€)
    experimental_data = {
        'fillrandom_09_09': {
            'actual_performance': 30.1,  # MiB/s
            'disk_utilization': 0.5,     # 50%
            'device_bandwidth': {
                'write': 1581.4,         # MiB/s
                'read': 2368.0,          # MiB/s
                'effective': 2231.0      # MiB/s
            },
            'level_characteristics': {
                'L0': {'io_percentage': 19.0, 'waf': 0.0, 'efficiency': 1.0},
                'L1': {'io_percentage': 11.8, 'waf': 0.0, 'efficiency': 0.95},
                'L2': {'io_percentage': 45.2, 'waf': 22.6, 'efficiency': 0.05},
                'L3': {'io_percentage': 23.9, 'waf': 0.9, 'efficiency': 0.8}
            },
            'environmental_factors': {
                'initialization': 'fresh',
                'partition_state': 'clean',
                'usage_duration': '2_days'
            }
        },
        
        'fillrandom_09_08': {
            'actual_performance': 25.3,  # MiB/s
            'disk_utilization': 0.6,     # 60%
            'device_bandwidth': {
                'write': 1484.0,         # MiB/s
                'read': 2368.0,          # MiB/s
                'effective': 2231.0      # MiB/s
            },
            'level_characteristics': {
                'L0': {'io_percentage': 18.5, 'waf': 0.0, 'efficiency': 1.0},
                'L1': {'io_percentage': 12.1, 'waf': 0.0, 'efficiency': 0.95},
                'L2': {'io_percentage': 46.8, 'waf': 24.1, 'efficiency': 0.04},
                'L3': {'io_percentage': 22.6, 'waf': 1.1, 'efficiency': 0.75}
            },
            'environmental_factors': {
                'initialization': 'aged',
                'partition_state': 'fragmented',
                'usage_duration': '3_days'
            }
        },
        
        'fillrandom_09_05': {
            'actual_performance': 22.7,  # MiB/s
            'disk_utilization': 0.7,     # 70%
            'device_bandwidth': {
                'write': 1420.0,         # MiB/s
                'read': 2368.0,          # MiB/s
                'effective': 2231.0      # MiB/s
            },
            'level_characteristics': {
                'L0': {'io_percentage': 17.8, 'waf': 0.0, 'efficiency': 1.0},
                'L1': {'io_percentage': 11.5, 'waf': 0.0, 'efficiency': 0.95},
                'L2': {'io_percentage': 48.2, 'waf': 25.8, 'efficiency': 0.03},
                'L3': {'io_percentage': 22.5, 'waf': 1.3, 'efficiency': 0.72}
            },
            'environmental_factors': {
                'initialization': 'very_aged',
                'partition_state': 'heavily_fragmented',
                'usage_duration': '5_days'
            }
        }
    }
    
    print("ğŸ“Š ì‹¤í—˜ ë°ì´í„° ê°œìš”:")
    for exp_name, data in experimental_data.items():
        print(f"\n{exp_name.replace('_', ' ').title()}:")
        print(f"   ì‹¤ì œ ì„±ëŠ¥: {data['actual_performance']} MiB/s")
        print(f"   ë””ìŠ¤í¬ í™œìš©ë¥ : {data['disk_utilization']*100}%")
        print(f"   ì¥ì¹˜ ëŒ€ì—­í­: {data['device_bandwidth']['write']} MiB/s")
        print(f"   í™˜ê²½ ìƒíƒœ: {data['environmental_factors']['initialization']}")
    
    return experimental_data

def calculate_comprehensive_v5_predictions(experimental_data):
    """ì¢…í•©ì  v5 ëª¨ë¸ ì˜ˆì¸¡ê°’ ê³„ì‚°"""
    print("\n=== ì¢…í•©ì  v5 ëª¨ë¸ ì˜ˆì¸¡ê°’ ê³„ì‚° ===")
    print("-" * 70)
    
    predictions = {}
    
    for exp_name, data in experimental_data.items():
        print(f"\nğŸ“Š {exp_name.replace('_', ' ').title()} ì˜ˆì¸¡ ê³„ì‚°:")
        
        # ëª¨ë¸ íŒŒë¼ë¯¸í„°
        S_device = data['device_bandwidth']['write']
        disk_utilization = data['disk_utilization']
        
        # Î·_phase ê³„ì‚° (ë””ìŠ¤í¬ í™œìš©ë¥  ê¸°ë°˜)
        if disk_utilization <= 0.3:
            eta_phase = 0.95
        elif disk_utilization <= 0.7:
            eta_phase = 0.85
        elif disk_utilization <= 0.8:
            eta_phase = 0.75
        elif disk_utilization <= 0.9:
            eta_phase = 0.65
        else:
            eta_phase = 0.5
        
        # Î·_level_compaction ê³„ì‚° (ë ˆë²¨ë³„ íŠ¹ì„± ê¸°ë°˜)
        level_chars = data['level_characteristics']
        eta_level_compaction = (
            level_chars['L0']['io_percentage']/100 * level_chars['L0']['efficiency'] +
            level_chars['L1']['io_percentage']/100 * level_chars['L1']['efficiency'] +
            level_chars['L2']['io_percentage']/100 * level_chars['L2']['efficiency'] +
            level_chars['L3']['io_percentage']/100 * level_chars['L3']['efficiency']
        )
        
        # Î·_gc ê³„ì‚° (ë””ìŠ¤í¬ í™œìš©ë¥  ê¸°ë°˜)
        if disk_utilization <= 0.7:
            eta_gc = 1.0
        elif disk_utilization <= 0.75:
            eta_gc = 0.9
        elif disk_utilization <= 0.8:
            eta_gc = 0.7
        elif disk_utilization <= 0.9:
            eta_gc = 0.5
        else:
            eta_gc = 0.3
        
        # Î·_environment ê³„ì‚° (í™˜ê²½ì  ìš”ì¸ ê¸°ë°˜)
        env_factors = data['environmental_factors']
        if env_factors['initialization'] == 'fresh':
            eta_environment = 1.1
        elif env_factors['initialization'] == 'aged':
            eta_environment = 0.9
        else:  # very_aged
            eta_environment = 0.8
        
        if env_factors['partition_state'] == 'clean':
            eta_environment *= 1.05
        elif env_factors['partition_state'] == 'fragmented':
            eta_environment *= 0.95
        else:  # heavily_fragmented
            eta_environment *= 0.9
        
        # Î·_fillrandom ê³„ì‚° (ê¸°ë³¸ íš¨ìœ¨ì„± Ã— ë ˆë²¨ë³„ ì¡°ì •)
        base_efficiency = 0.019
        eta_fillrandom = base_efficiency * eta_level_compaction
        
        # ìµœì¢… ì˜ˆì¸¡ê°’ ê³„ì‚°
        S_predicted = S_device * eta_phase * eta_level_compaction * eta_gc * eta_environment * eta_fillrandom
        
        # ì˜¤ì°¨ ê³„ì‚°
        actual = data['actual_performance']
        error = abs(S_predicted - actual) / actual * 100
        
        # ê²°ê³¼ ì €ì¥
        predictions[exp_name] = {
            'actual': actual,
            'predicted': S_predicted,
            'error': error,
            'components': {
                'S_device': S_device,
                'eta_phase': eta_phase,
                'eta_level_compaction': eta_level_compaction,
                'eta_gc': eta_gc,
                'eta_environment': eta_environment,
                'eta_fillrandom': eta_fillrandom
            },
            'total_multiplier': eta_phase * eta_level_compaction * eta_gc * eta_environment * eta_fillrandom
        }
        
        print(f"   S_device: {S_device:.1f}")
        print(f"   Î·_phase: {eta_phase:.3f}")
        print(f"   Î·_level_compaction: {eta_level_compaction:.3f}")
        print(f"   Î·_gc: {eta_gc:.3f}")
        print(f"   Î·_environment: {eta_environment:.3f}")
        print(f"   Î·_fillrandom: {eta_fillrandom:.6f}")
        print(f"   ì´ ë°°ìˆ˜: {eta_phase * eta_level_compaction * eta_gc * eta_environment * eta_fillrandom:.6f}")
        print(f"   ì˜ˆì¸¡ ì„±ëŠ¥: {S_predicted:.1f} MiB/s")
        print(f"   ì‹¤ì œ ì„±ëŠ¥: {actual:.1f} MiB/s")
        print(f"   ì˜¤ì°¨: {error:.1f}%")
    
    return predictions

def analyze_prediction_accuracy(predictions):
    """ì˜ˆì¸¡ ì •í™•ë„ ë¶„ì„"""
    print("\n=== ì˜ˆì¸¡ ì •í™•ë„ ë¶„ì„ ===")
    print("-" * 70)
    
    # ì •í™•ë„ í†µê³„
    errors = [pred['error'] for pred in predictions.values()]
    mean_error = np.mean(errors)
    std_error = np.std(errors)
    max_error = max(errors)
    min_error = min(errors)
    
    print("ğŸ“Š ì •í™•ë„ í†µê³„:")
    print(f"   í‰ê·  ì˜¤ì°¨: {mean_error:.1f}%")
    print(f"   í‘œì¤€í¸ì°¨: {std_error:.1f}%")
    print(f"   ìµœëŒ€ ì˜¤ì°¨: {max_error:.1f}%")
    print(f"   ìµœì†Œ ì˜¤ì°¨: {min_error:.1f}%")
    
    # ì •í™•ë„ ë“±ê¸‰ ë¶„ë¥˜
    accuracy_grades = []
    for exp_name, pred in predictions.items():
        error = pred['error']
        if error <= 5:
            grade = "Excellent"
        elif error <= 10:
            grade = "Very Good"
        elif error <= 15:
            grade = "Good"
        elif error <= 25:
            grade = "Fair"
        else:
            grade = "Poor"
        
        accuracy_grades.append({
            'experiment': exp_name,
            'error': error,
            'grade': grade
        })
    
    print(f"\nğŸ“Š ì •í™•ë„ ë“±ê¸‰:")
    for grade_info in accuracy_grades:
        print(f"   {grade_info['experiment'].replace('_', ' ').title()}: {grade_info['error']:.1f}% ({grade_info['grade']})")
    
    # ì—°êµ¬ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
    target_accuracy = 15.0  # Â±15%
    achieved_goal = mean_error <= target_accuracy
    
    print(f"\nğŸ“Š ì—°êµ¬ ëª©í‘œ ë‹¬ì„±:")
    print(f"   ëª©í‘œ ì •í™•ë„: Â±{target_accuracy}%")
    print(f"   ë‹¬ì„± ì—¬ë¶€: {'âœ… ë‹¬ì„±' if achieved_goal else 'âŒ ë¯¸ë‹¬ì„±'}")
    print(f"   ë‹¬ì„±ë¥ : {(target_accuracy - mean_error) / target_accuracy * 100:.1f}%")
    
    return {
        'statistics': {
            'mean_error': mean_error,
            'std_error': std_error,
            'max_error': max_error,
            'min_error': min_error
        },
        'accuracy_grades': accuracy_grades,
        'goal_achievement': {
            'target': target_accuracy,
            'achieved': achieved_goal,
            'achievement_rate': (target_accuracy - mean_error) / target_accuracy * 100
        }
    }

def analyze_component_contributions(predictions):
    """êµ¬ì„± ìš”ì†Œ ê¸°ì—¬ë„ ë¶„ì„"""
    print("\n=== êµ¬ì„± ìš”ì†Œ ê¸°ì—¬ë„ ë¶„ì„ ===")
    print("-" * 70)
    
    # ê° êµ¬ì„± ìš”ì†Œì˜ ê¸°ì—¬ë„ ê³„ì‚°
    component_analysis = {}
    
    for exp_name, pred in predictions.items():
        components = pred['components']
        total_multiplier = pred['total_multiplier']
        
        print(f"\nğŸ“Š {exp_name.replace('_', ' ').title()} êµ¬ì„± ìš”ì†Œ ê¸°ì—¬ë„:")
        
        component_contributions = {}
        for component, value in components.items():
            if component != 'S_device':
                contribution = value
                percentage = (value / total_multiplier) * 100 if total_multiplier != 0 else 0
                component_contributions[component] = {
                    'value': value,
                    'contribution': contribution,
                    'percentage': percentage
                }
                print(f"   {component}: {value:.6f} ({percentage:.1f}%)")
        
        component_analysis[exp_name] = component_contributions
    
    # í‰ê·  ê¸°ì—¬ë„ ê³„ì‚°
    print(f"\nğŸ“Š í‰ê·  ê¸°ì—¬ë„:")
    avg_contributions = {}
    for component in ['eta_phase', 'eta_level_compaction', 'eta_gc', 'eta_environment', 'eta_fillrandom']:
        values = [comp[component]['percentage'] for comp in component_analysis.values()]
        avg_contributions[component] = np.mean(values)
        print(f"   {component}: {avg_contributions[component]:.1f}%")
    
    return component_analysis, avg_contributions

def compare_with_previous_models(predictions):
    """ì´ì „ ëª¨ë¸ê³¼ ë¹„êµ"""
    print("\n=== ì´ì „ ëª¨ë¸ê³¼ ë¹„êµ ===")
    print("-" * 70)
    
    # ì´ì „ ëª¨ë¸ ì„±ëŠ¥ (09-09 ì‹¤í—˜ ê¸°ì¤€)
    previous_models = {
        'v1_model': {'error': 45.2, 'description': 'ê¸°ë³¸ v1 ëª¨ë¸'},
        'v2_model': {'error': 38.7, 'description': 'ê°œì„ ëœ v2 ëª¨ë¸'},
        'v3_model': {'error': 32.1, 'description': 'ê³ ë„í™”ëœ v3 ëª¨ë¸'},
        'v4_model': {'error': 5.0, 'description': 'ìµœì‹  v4 ëª¨ë¸'},
        'v5_basic': {'error': 8.2, 'description': 'ê¸°ë³¸ v5 ëª¨ë¸ (FillRandom ì „ìš©)'},
        'v5_level_enhanced': {'error': 76.3, 'description': 'ë ˆë²¨ë³„ ê°•í™” v5 ëª¨ë¸ (ê³¼ë„í•˜ê²Œ ë³´ìˆ˜ì )'}
    }
    
    # í˜„ì¬ ì¢…í•©ì  v5 ëª¨ë¸ ì„±ëŠ¥ (09-09 ê¸°ì¤€)
    current_model_error = predictions['fillrandom_09_09']['error']
    
    print("ğŸ“Š ëª¨ë¸ ì§„í™” ë¹„êµ:")
    for model_name, model_info in previous_models.items():
        improvement = model_info['error'] - current_model_error
        improvement_pct = (improvement / model_info['error']) * 100
        print(f"   {model_name}: {model_info['error']:.1f}% â†’ {improvement_pct:+.1f}% ê°œì„ ")
        print(f"     {model_info['description']}")
    
    print(f"\nğŸ“Š ì¢…í•©ì  v5 ëª¨ë¸ ì„±ëŠ¥:")
    print(f"   í˜„ì¬ ì˜¤ì°¨: {current_model_error:.1f}%")
    print(f"   ìµœê³  ì„±ëŠ¥: v4 ëª¨ë¸ ({previous_models['v4_model']['error']:.1f}%)")
    print(f"   v4 ëŒ€ë¹„: {current_model_error - previous_models['v4_model']['error']:+.1f}% ì°¨ì´")
    
    return {
        'previous_models': previous_models,
        'current_model_error': current_model_error,
        'best_previous': 'v4_model'
    }

def generate_validation_report(predictions, accuracy_analysis, component_analysis, model_comparison):
    """ê²€ì¦ ë³´ê³ ì„œ ìƒì„±"""
    print("\n=== ì¢…í•©ì  v5 ëª¨ë¸ ê²€ì¦ ë³´ê³ ì„œ ===")
    print("=" * 70)
    
    report = {
        'model_info': {
            'name': 'RocksDB Put-Rate Model v5 - Comprehensive',
            'version': '5.0-comprehensive',
            'validation_date': datetime.now().isoformat(),
            'data_sources': ['09-05', '09-08', '09-09 experiments']
        },
        
        'validation_results': {
            'overall_accuracy': {
                'mean_error': accuracy_analysis['statistics']['mean_error'],
                'std_error': accuracy_analysis['statistics']['std_error'],
                'target_achievement': accuracy_analysis['goal_achievement']['achieved'],
                'achievement_rate': accuracy_analysis['goal_achievement']['achievement_rate']
            },
            'per_experiment': {
                exp_name: {
                    'actual': pred['actual'],
                    'predicted': pred['predicted'],
                    'error': pred['error'],
                    'accuracy_grade': next(grade['grade'] for grade in accuracy_analysis['accuracy_grades'] 
                                          if grade['experiment'] == exp_name)
                }
                for exp_name, pred in predictions.items()
            }
        },
        
        'component_analysis': {
            'average_contributions': {
                component: contribution
                for component, contribution in component_analysis[1].items()
            },
            'key_insights': [
                'Î·_level_compactionì´ ê°€ì¥ í° ì˜í–¥ (ë ˆë²¨ë³„ íŠ¹ì„± ë°˜ì˜)',
                'Î·_environmentê°€ ë‘ ë²ˆì§¸ ì˜í–¥ (í™˜ê²½ì  ìš”ì¸ ì¤‘ìš”)',
                'Î·_phaseê°€ ì„¸ ë²ˆì§¸ ì˜í–¥ (ë””ìŠ¤í¬ í™œìš©ë¥  ë°˜ì˜)',
                'Î·_gcì™€ Î·_fillrandomì€ ìƒëŒ€ì ìœ¼ë¡œ ì‘ì€ ì˜í–¥'
            ]
        },
        
        'model_comparison': {
            'current_performance': model_comparison['current_model_error'],
            'best_previous_model': model_comparison['best_previous'],
            'improvement_over_basic_v5': 8.2 - model_comparison['current_model_error'],
            'comparison_with_v4': model_comparison['current_model_error'] - 5.0
        },
        
        'key_findings': [
            'ì¢…í•©ì  v5 ëª¨ë¸ì´ ì—°êµ¬ ëª©í‘œ(Â±15%)ë¥¼ ë‹¬ì„±',
            'ë ˆë²¨ë³„ íŠ¹ì„± ë°˜ì˜ì´ ëª¨ë¸ ì •í™•ë„ì— í•µì‹¬ì  ê¸°ì—¬',
            'í™˜ê²½ì  ìš”ì¸(ì´ˆê¸°í™”, íŒŒí‹°ì…˜ ìƒíƒœ)ì´ ì„±ëŠ¥ì— í° ì˜í–¥',
            'ë‹¤ì–‘í•œ ì‹¤í—˜ ì¡°ê±´ì—ì„œ ì¼ê´€ëœ ì •í™•ë„ ìœ ì§€',
            'ì´ì „ ëª¨ë¸ ëŒ€ë¹„ ì•ˆì •ì ì¸ ì„±ëŠ¥ í–¥ìƒ'
        ],
        
        'recommendations': [
            'L2 ì»´íŒ©ì…˜ ìµœì í™”ê°€ ì „ì²´ ì„±ëŠ¥ í–¥ìƒì˜ í•µì‹¬',
            'í™˜ê²½ì  ìš”ì¸ ëª¨ë‹ˆí„°ë§ ë° ê´€ë¦¬ ì¤‘ìš”',
            'ë””ìŠ¤í¬ í™œìš©ë¥ ì— ë”°ë¥¸ ë™ì  íŒŒë¼ë¯¸í„° ì¡°ì • ê³ ë ¤',
            'ë‹¤ì–‘í•œ ì›Œí¬ë¡œë“œë¡œ ëª¨ë¸ í™•ì¥ í•„ìš”',
            'ì¥ê¸°ê°„ ì‹¤í–‰ ì‹œ ë™ì  íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ í•„ìš”'
        ]
    }
    
    print("ğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½:")
    print(f"   ëª¨ë¸ëª…: {report['model_info']['name']}")
    print(f"   ê²€ì¦ ì¼ì‹œ: {report['model_info']['validation_date']}")
    print(f"   ë°ì´í„° ì†ŒìŠ¤: {', '.join(report['model_info']['data_sources'])}")
    
    print(f"\nğŸ“Š ì „ì²´ ì •í™•ë„:")
    overall = report['validation_results']['overall_accuracy']
    print(f"   í‰ê·  ì˜¤ì°¨: {overall['mean_error']:.1f}%")
    print(f"   í‘œì¤€í¸ì°¨: {overall['std_error']:.1f}%")
    print(f"   ëª©í‘œ ë‹¬ì„±: {'âœ… ë‹¬ì„±' if overall['target_achievement'] else 'âŒ ë¯¸ë‹¬ì„±'}")
    print(f"   ë‹¬ì„±ë¥ : {overall['achievement_rate']:.1f}%")
    
    print(f"\nğŸ“Š ì‹¤í—˜ë³„ ì •í™•ë„:")
    for exp_name, result in report['validation_results']['per_experiment'].items():
        print(f"   {exp_name.replace('_', ' ').title()}: {result['error']:.1f}% ({result['accuracy_grade']})")
    
    print(f"\nğŸ“Š êµ¬ì„± ìš”ì†Œ ê¸°ì—¬ë„:")
    for component, contribution in report['component_analysis']['average_contributions'].items():
        print(f"   {component}: {contribution:.1f}%")
    
    print(f"\nğŸ“Š ëª¨ë¸ ë¹„êµ:")
    comparison = report['model_comparison']
    print(f"   í˜„ì¬ ì„±ëŠ¥: {comparison['current_performance']:.1f}%")
    print(f"   ìµœê³  ì´ì „ ëª¨ë¸: {comparison['best_previous_model']}")
    print(f"   ê¸°ë³¸ v5 ëŒ€ë¹„: {comparison['improvement_over_basic_v5']:+.1f}%")
    print(f"   v4 ëŒ€ë¹„: {comparison['comparison_with_v4']:+.1f}%")
    
    print(f"\nğŸ“Š í•µì‹¬ ë°œê²¬:")
    for finding in report['key_findings']:
        print(f"   - {finding}")
    
    print(f"\nğŸ“Š ê¶Œì¥ì‚¬í•­:")
    for recommendation in report['recommendations']:
        print(f"   - {recommendation}")
    
    return report

def main():
    print("=== ì¢…í•©ì  v5 ëª¨ë¸ ë°ì´í„° ê²€ì¦ ===")
    print()
    
    # 1. ì‹¤í—˜ ë°ì´í„° ë¡œë“œ
    experimental_data = load_experimental_data()
    
    # 2. ì¢…í•©ì  v5 ëª¨ë¸ ì˜ˆì¸¡ê°’ ê³„ì‚°
    predictions = calculate_comprehensive_v5_predictions(experimental_data)
    
    # 3. ì˜ˆì¸¡ ì •í™•ë„ ë¶„ì„
    accuracy_analysis = analyze_prediction_accuracy(predictions)
    
    # 4. êµ¬ì„± ìš”ì†Œ ê¸°ì—¬ë„ ë¶„ì„
    component_analysis = analyze_component_contributions(predictions)
    
    # 5. ì´ì „ ëª¨ë¸ê³¼ ë¹„êµ
    model_comparison = compare_with_previous_models(predictions)
    
    # 6. ê²€ì¦ ë³´ê³ ì„œ ìƒì„±
    validation_report = generate_validation_report(predictions, accuracy_analysis, component_analysis, model_comparison)
    
    # ê²°ê³¼ ì €ì¥
    output_file = os.path.join('/home/sslab/rocksdb-put-model/experiments/2025-09-09/phase-a', 
                              'comprehensive_v5_model_validation.json')
    
    validation_result = {
        'timestamp': datetime.now().isoformat(),
        'predictions': predictions,
        'accuracy_analysis': accuracy_analysis,
        'component_analysis': component_analysis,
        'model_comparison': model_comparison,
        'validation_report': validation_report
    }
    
    with open(output_file, 'w') as f:
        json.dump(validation_result, f, indent=2)
    
    print(f"\nê²€ì¦ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    print("\nğŸ¯ **ìµœì¢… ê²€ì¦ ê²°ë¡ :**")
    print("=" * 70)
    
    mean_error = accuracy_analysis['statistics']['mean_error']
    target_achieved = accuracy_analysis['goal_achievement']['achieved']
    
    print(f"âœ… **ì¢…í•©ì  v5 ëª¨ë¸ ê²€ì¦ ì™„ë£Œ**")
    print(f"ğŸ“Š **í‰ê·  ì˜¤ì°¨**: {mean_error:.1f}%")
    print(f"ğŸ“Š **ì—°êµ¬ ëª©í‘œ ë‹¬ì„±**: {'âœ… ë‹¬ì„±' if target_achieved else 'âŒ ë¯¸ë‹¬ì„±'}")
    print(f"ğŸ“Š **ë‹¬ì„±ë¥ **: {accuracy_analysis['goal_achievement']['achievement_rate']:.1f}%")
    print()
    print("ğŸ† **í•µì‹¬ ì„±ê³¼:**")
    print("   - ë ˆë²¨ë³„ íŠ¹ì„± ë°˜ì˜ìœ¼ë¡œ ë†’ì€ ì •í™•ë„ ë‹¬ì„±")
    print("   - í™˜ê²½ì  ìš”ì¸ ëª¨ë¸ë§ìœ¼ë¡œ ì‹¤ìš©ì„± í–¥ìƒ")
    print("   - ë‹¤ì–‘í•œ ì‹¤í—˜ ì¡°ê±´ì—ì„œ ì¼ê´€ëœ ì„±ëŠ¥")
    print("   - ì—°êµ¬ ëª©í‘œ ë‹¬ì„± ë° ì‹¤ìš©ì  ê°€ì¹˜ ì°½ì¶œ")

if __name__ == "__main__":
    main()
