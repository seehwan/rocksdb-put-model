#!/usr/bin/env python3
"""
Phase-D ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸
"""

import os
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

class PhaseDAnalyzer:
    def __init__(self):
        self.results_dir = '/home/sslab/rocksdb-put-model/experiments/2025-09-12/phase-d/results'
        self.data = {}
        
    def load_results(self):
        """Phase-D ê²°ê³¼ ë°ì´í„° ë¡œë“œ"""
        print("ğŸ“Š Phase-D ê²°ê³¼ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ê° ê²°ê³¼ íŒŒì¼ ë¡œë“œ
        files = {
            'phase_d_report': 'phase_d_report.json',
            'integration_results': 'integration_results.json',
            'performance_report': 'performance_report.json',
            'auto_tuning_records': 'auto_tuning_records.json',
            'real_time_metrics': 'real_time_metrics.json',
            'model_deployment': 'model_deployment.json'
        }
        
        for key, filename in files.items():
            filepath = os.path.join(self.results_dir, filename)
            if os.path.exists(filepath):
                with open(filepath, 'r') as f:
                    self.data[key] = json.load(f)
                print(f"âœ… {filename} ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"âŒ {filename} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        print(f"ğŸ“Š ì´ {len(self.data)} ê°œ ê²°ê³¼ íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
    
    def analyze_performance_metrics(self):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¶„ì„"""
        print("ğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¶„ì„ ì¤‘...")
        
        if 'integration_results' not in self.data:
            print("âŒ í†µí•© ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df = pd.DataFrame(self.data['integration_results'])
        
        # ë©”íŠ¸ë¦­ ë¶„ì„
        analysis = {
            'total_loops': len(df),
            'time_span': {
                'start': df['timestamp'].min(),
                'end': df['timestamp'].max()
            },
            'qps_analysis': {
                'mean': df['metrics'].apply(lambda x: x['qps']).mean(),
                'std': df['metrics'].apply(lambda x: x['qps']).std(),
                'min': df['metrics'].apply(lambda x: x['qps']).min(),
                'max': df['metrics'].apply(lambda x: x['qps']).max(),
                'trend': 'stable' if df['metrics'].apply(lambda x: x['qps']).std() < 200 else 'variable'
            },
            'latency_analysis': {
                'mean': df['metrics'].apply(lambda x: x['latency']).mean(),
                'std': df['metrics'].apply(lambda x: x['latency']).std(),
                'min': df['metrics'].apply(lambda x: x['latency']).min(),
                'max': df['metrics'].apply(lambda x: x['latency']).max(),
                'trend': 'stable' if df['metrics'].apply(lambda x: x['latency']).std() < 0.5 else 'variable'
            },
            'prediction_accuracy': {
                'mean_prediction': df['prediction'].mean(),
                'prediction_std': df['prediction'].std(),
                'prediction_consistency': 'high' if df['prediction'].std() < 1.0 else 'low'
            }
        }
        
        return analysis
    
    def analyze_auto_tuning(self):
        """ìë™ íŠœë‹ ë¶„ì„"""
        print("ğŸ”§ ìë™ íŠœë‹ ë¶„ì„ ì¤‘...")
        
        if 'auto_tuning_records' not in self.data:
            print("âŒ ìë™ íŠœë‹ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        tuning_data = self.data['auto_tuning_records']
        
        analysis = {
            'total_adjustments': len(tuning_data),
            'models_tuned': list(set([record.get('model', 'unknown') for record in tuning_data])),
            'parameter_changes': self._analyze_parameter_changes(tuning_data),
            'tuning_effectiveness': self._assess_tuning_effectiveness(tuning_data)
        }
        
        return analysis
    
    def _analyze_parameter_changes(self, tuning_data):
        """íŒŒë¼ë¯¸í„° ë³€í™” ë¶„ì„"""
        if not tuning_data:
            return {}
        
        # íŒŒë¼ë¯¸í„° ë³€í™” ì¶”ì 
        parameter_changes = {}
        
        for record in tuning_data:
            if 'adjusted_parameters' in record:
                for param, value in record['adjusted_parameters'].items():
                    if param not in parameter_changes:
                        parameter_changes[param] = []
                    parameter_changes[param].append(value)
        
        # ë³€í™” í†µê³„ ê³„ì‚°
        changes_stats = {}
        for param, values in parameter_changes.items():
            changes_stats[param] = {
                'count': len(values),
                'mean': np.mean(values),
                'std': np.std(values),
                'min': np.min(values),
                'max': np.max(values),
                'variability': 'high' if np.std(values) > 0.2 else 'low'
            }
        
        return changes_stats
    
    def _assess_tuning_effectiveness(self, tuning_data):
        """íŠœë‹ íš¨ê³¼ì„± í‰ê°€"""
        if len(tuning_data) < 2:
            return {'status': 'insufficient_data'}
        
        # ì„±ëŠ¥ ê°œì„  ì¶”ì„¸ ë¶„ì„
        performance_trends = []
        for record in tuning_data:
            if 'performance_data' in record:
                perf_data = record['performance_data']
                if 'accuracy' in perf_data:
                    performance_trends.append(perf_data['accuracy'])
        
        if len(performance_trends) >= 2:
            trend = 'improving' if performance_trends[-1] > performance_trends[0] else 'degrading'
            improvement = performance_trends[-1] - performance_trends[0]
        else:
            trend = 'unknown'
            improvement = 0
        
        return {
            'trend': trend,
            'improvement': improvement,
            'effectiveness': 'high' if improvement > 0.1 else 'moderate' if improvement > 0 else 'low'
        }
    
    def create_visualizations(self):
        """ì‹œê°í™” ìƒì„±"""
        print("ğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...")
        
        if 'integration_results' not in self.data:
            print("âŒ í†µí•© ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë°ì´í„° ì¤€ë¹„
        df = pd.DataFrame(self.data['integration_results'])
        
        # ë©”íŠ¸ë¦­ ì¶”ì¶œ
        df['qps'] = df['metrics'].apply(lambda x: x['qps'])
        df['latency'] = df['metrics'].apply(lambda x: x['latency'])
        df['cpu_usage'] = df['metrics'].apply(lambda x: x['cpu_usage'])
        df['memory_usage'] = df['metrics'].apply(lambda x: x['memory_usage'])
        df['io_utilization'] = df['metrics'].apply(lambda x: x['io_utilization'])
        df['compaction_activity'] = df['metrics'].apply(lambda x: x['compaction_activity'])
        
        # ì‹œê°í™” ìƒì„±
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('Phase-D: Enhanced Models Production Integration Results', fontsize=16, fontweight='bold')
        
        # 1. QPS íŠ¸ë Œë“œ
        axes[0, 0].plot(range(len(df)), df['qps'], marker='o', linewidth=2, markersize=6)
        axes[0, 0].set_title('QPS Trend Over Time')
        axes[0, 0].set_xlabel('Loop Count')
        axes[0, 0].set_ylabel('QPS')
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. ì§€ì—°ì‹œê°„ íŠ¸ë Œë“œ
        axes[0, 1].plot(range(len(df)), df['latency'], marker='s', color='red', linewidth=2, markersize=6)
        axes[0, 1].set_title('Latency Trend Over Time')
        axes[0, 1].set_xlabel('Loop Count')
        axes[0, 1].set_ylabel('Latency (ms)')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ 
        axes[0, 2].plot(range(len(df)), df['cpu_usage'], marker='o', label='CPU Usage', linewidth=2)
        axes[0, 2].plot(range(len(df)), df['memory_usage'], marker='s', label='Memory Usage', linewidth=2)
        axes[0, 2].set_title('System Resource Usage')
        axes[0, 2].set_xlabel('Loop Count')
        axes[0, 2].set_ylabel('Usage (%)')
        axes[0, 2].legend()
        axes[0, 2].grid(True, alpha=0.3)
        
        # 4. I/O ë° ì»´íŒ©ì…˜ í™œë™
        axes[1, 0].plot(range(len(df)), df['io_utilization'], marker='o', label='I/O Utilization', linewidth=2)
        axes[1, 0].plot(range(len(df)), df['compaction_activity'], marker='s', label='Compaction Activity', linewidth=2)
        axes[1, 0].set_title('I/O and Compaction Activity')
        axes[1, 0].set_xlabel('Loop Count')
        axes[1, 0].set_ylabel('Activity (%)')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # 5. ì˜ˆì¸¡ vs ì‹¤ì œ ì„±ëŠ¥
        axes[1, 1].plot(range(len(df)), df['qps'], marker='o', label='Actual QPS', linewidth=2)
        axes[1, 1].axhline(y=df['prediction'].iloc[0], color='red', linestyle='--', label=f'Predicted S_max: {df["prediction"].iloc[0]:.1f}')
        axes[1, 1].set_title('Predicted vs Actual Performance')
        axes[1, 1].set_xlabel('Loop Count')
        axes[1, 1].set_ylabel('QPS')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        # 6. ì„±ëŠ¥ ë¶„í¬
        axes[1, 2].hist(df['qps'], bins=10, alpha=0.7, color='skyblue', edgecolor='black')
        axes[1, 2].axvline(df['qps'].mean(), color='red', linestyle='--', label=f'Mean: {df["qps"].mean():.1f}')
        axes[1, 2].set_title('QPS Distribution')
        axes[1, 2].set_xlabel('QPS')
        axes[1, 2].set_ylabel('Frequency')
        axes[1, 2].legend()
        axes[1, 2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ì‹œê°í™” ì €ì¥
        output_file = os.path.join(self.results_dir, 'phase_d_analysis_visualization.png')
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"âœ… ì‹œê°í™” ì €ì¥: {output_file}")
        
        plt.show()
    
    def generate_comprehensive_report(self):
        """ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        print("ğŸ“ Phase-D ì¢…í•© ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        # ë¶„ì„ ìˆ˜í–‰
        performance_analysis = self.analyze_performance_metrics()
        tuning_analysis = self.analyze_auto_tuning()
        
        # ë³´ê³ ì„œ ìƒì„±
        report = {
            'phase_d_summary': {
                'phase': 'Phase-D: Enhanced Models Production Integration',
                'execution_time': datetime.now().isoformat(),
                'status': 'completed',
                'objectives_achieved': [
                    'Production Integration',
                    'Real-time Monitoring',
                    'Auto-tuning',
                    'Performance Validation'
                ]
            },
            'performance_analysis': performance_analysis,
            'auto_tuning_analysis': tuning_analysis,
            'key_findings': self._generate_key_findings(performance_analysis, tuning_analysis),
            'recommendations': self._generate_recommendations(performance_analysis, tuning_analysis)
        }
        
        # ë³´ê³ ì„œ ì €ì¥
        report_file = os.path.join(self.results_dir, 'phase_d_comprehensive_report.json')
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"âœ… ì¢…í•© ë³´ê³ ì„œ ìƒì„±: {report_file}")
        
        return report
    
    def _generate_key_findings(self, performance_analysis, tuning_analysis):
        """ì£¼ìš” ë°œê²¬ì‚¬í•­ ìƒì„±"""
        findings = []
        
        if performance_analysis:
            qps_trend = performance_analysis['qps_analysis']['trend']
            findings.append(f"QPS ì„±ëŠ¥ì´ {qps_trend} ìƒíƒœë¥¼ ìœ ì§€í–ˆìŠµë‹ˆë‹¤.")
            
            prediction_consistency = performance_analysis['prediction_accuracy']['prediction_consistency']
            findings.append(f"ëª¨ë¸ ì˜ˆì¸¡ì˜ ì¼ê´€ì„±ì´ {prediction_consistency} ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
        
        if tuning_analysis:
            total_adjustments = tuning_analysis['total_adjustments']
            findings.append(f"ì´ {total_adjustments} íšŒì˜ ìë™ íŒŒë¼ë¯¸í„° ì¡°ì •ì´ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            if 'tuning_effectiveness' in tuning_analysis:
                effectiveness = tuning_analysis['tuning_effectiveness']['effectiveness']
                findings.append(f"ìë™ íŠœë‹ì˜ íš¨ê³¼ì„±ì€ {effectiveness} ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
        
        return findings
    
    def _generate_recommendations(self, performance_analysis, tuning_analysis):
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if performance_analysis:
            qps_std = performance_analysis['qps_analysis']['std']
            if qps_std > 200:
                recommendations.append("QPS ë³€ë™ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ì•ˆì •ì„± ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            
            latency_std = performance_analysis['latency_analysis']['std']
            if latency_std > 0.5:
                recommendations.append("ì§€ì—°ì‹œê°„ ë³€ë™ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì„±ëŠ¥ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        if tuning_analysis and 'parameter_changes' in tuning_analysis:
            high_variability_params = [
                param for param, stats in tuning_analysis['parameter_changes'].items()
                if stats['variability'] == 'high'
            ]
            if high_variability_params:
                recommendations.append(f"ë‹¤ìŒ íŒŒë¼ë¯¸í„°ë“¤ì˜ ë³€ë™ì„±ì´ ë†’ìŠµë‹ˆë‹¤: {', '.join(high_variability_params)}. íŠœë‹ ì•Œê³ ë¦¬ì¦˜ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        recommendations.append("í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œì˜ ì¥ê¸°ê°„ ëª¨ë‹ˆí„°ë§ì„ í†µí•´ ëª¨ë¸ ì„±ëŠ¥ì„ ì§€ì†ì ìœ¼ë¡œ ê²€ì¦í•˜ì„¸ìš”.")
        recommendations.append("ì‹¤ì œ ì›Œí¬ë¡œë“œì— ëŒ€í•œ ëª¨ë¸ ì ì‘ì„±ì„ ë”ìš± í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ì¶”ê°€ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        return recommendations

def main():
    """Phase-D ê²°ê³¼ ë¶„ì„ ë©”ì¸ ì‹¤í–‰"""
    print("ğŸ” Phase-D ê²°ê³¼ ë¶„ì„ ì‹œì‘")
    print("=" * 50)
    
    # ë¶„ì„ê¸° ìƒì„±
    analyzer = PhaseDAnalyzer()
    
    # ê²°ê³¼ ë¡œë“œ
    analyzer.load_results()
    
    # ì‹œê°í™” ìƒì„±
    analyzer.create_visualizations()
    
    # ì¢…í•© ë³´ê³ ì„œ ìƒì„±
    report = analyzer.generate_comprehensive_report()
    
    print("\n" + "=" * 50)
    print("ğŸ‰ Phase-D ê²°ê³¼ ë¶„ì„ ì™„ë£Œ!")
    print("=" * 50)

if __name__ == "__main__":
    main()
