#!/usr/bin/env python3
"""
Advanced Optimization Framework for Phase-E
Enhanced ëª¨ë¸ë“¤ì˜ ê³ ê¸‰ ìµœì í™”ë¥¼ ìœ„í•œ í”„ë ˆì„ì›Œí¬
"""

import os
import sys
import json
import numpy as np
import pandas as pd
from datetime import datetime
from scipy.optimize import minimize, differential_evolution
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

class AdvancedOptimizationFramework:
    def __init__(self):
        self.optimization_results = {}
        self.performance_history = []
        self.best_parameters = {}
        
        # ìµœì í™” ëŒ€ìƒ ëª¨ë¸ë“¤
        self.target_models = ['v1_enhanced', 'v2_1_enhanced', 'v3_enhanced', 'v4_enhanced', 'v5_enhanced']
        
        # ìµœì í™” ì•Œê³ ë¦¬ì¦˜ë“¤
        self.optimization_algorithms = {
            'gradient_descent': self._gradient_descent_optimization,
            'genetic_algorithm': self._genetic_algorithm_optimization,
            'bayesian_optimization': self._bayesian_optimization,
            'particle_swarm': self._particle_swarm_optimization
        }
    
    def analyze_model_accuracy(self, model_name, predictions, actual_values):
        """ëª¨ë¸ ì •í™•ë„ ë¶„ì„"""
        print(f"ğŸ” {model_name} ëª¨ë¸ ì •í™•ë„ ë¶„ì„ ì¤‘...")
        
        # numpy ë°°ì—´ë¡œ ë³€í™˜
        predictions = np.array(predictions)
        actual_values = np.array(actual_values)
        
        # ì •í™•ë„ ë©”íŠ¸ë¦­ ê³„ì‚°
        mse = mean_squared_error(actual_values, predictions)
        rmse = np.sqrt(mse)
        r2 = r2_score(actual_values, predictions)
        mae = np.mean(np.abs(actual_values - predictions))
        
        # ìƒëŒ€ ì˜¤ë¥˜ìœ¨ ê³„ì‚°
        relative_errors = np.abs((actual_values - predictions) / (actual_values + 1e-6)) * 100
        mean_relative_error = np.mean(relative_errors)
        
        accuracy_analysis = {
            'model': model_name,
            'mse': mse,
            'rmse': rmse,
            'r2_score': r2,
            'mae': mae,
            'mean_relative_error': mean_relative_error,
            'accuracy_level': self._classify_accuracy(r2, mean_relative_error)
        }
        
        print(f"âœ… {model_name} ì •í™•ë„ ë¶„ì„ ì™„ë£Œ:")
        print(f"   - RÂ² Score: {r2:.4f}")
        print(f"   - RMSE: {rmse:.4f}")
        print(f"   - í‰ê·  ìƒëŒ€ ì˜¤ë¥˜: {mean_relative_error:.2f}%")
        print(f"   - ì •í™•ë„ ìˆ˜ì¤€: {accuracy_analysis['accuracy_level']}")
        
        return accuracy_analysis
    
    def _classify_accuracy(self, r2, mean_relative_error):
        """ì •í™•ë„ ìˆ˜ì¤€ ë¶„ë¥˜"""
        if r2 > 0.9 and mean_relative_error < 10:
            return "Excellent"
        elif r2 > 0.8 and mean_relative_error < 20:
            return "Good"
        elif r2 > 0.6 and mean_relative_error < 40:
            return "Fair"
        else:
            return "Poor"
    
    def optimize_model_parameters(self, model_name, objective_function, parameter_bounds):
        """ëª¨ë¸ íŒŒë¼ë¯¸í„° ìµœì í™”"""
        print(f"ğŸ”§ {model_name} ëª¨ë¸ íŒŒë¼ë¯¸í„° ìµœì í™” ì¤‘...")
        
        optimization_results = {}
        
        for algo_name, algo_func in self.optimization_algorithms.items():
            print(f"   ğŸ“Š {algo_name} ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ ì¤‘...")
            
            try:
                result = algo_func(objective_function, parameter_bounds)
                optimization_results[algo_name] = {
                    'success': True,
                    'optimal_parameters': result['parameters'],
                    'optimal_value': result['value'],
                    'iterations': result.get('iterations', 0),
                    'convergence': result.get('convergence', False)
                }
                print(f"   âœ… {algo_name} ì™„ë£Œ: ìµœì ê°’ = {result['value']:.6f}")
                
            except Exception as e:
                optimization_results[algo_name] = {
                    'success': False,
                    'error': str(e)
                }
                print(f"   âŒ {algo_name} ì‹¤íŒ¨: {e}")
        
        # ìµœì  ê²°ê³¼ ì„ íƒ
        best_result = self._select_best_result(optimization_results)
        
        self.optimization_results[model_name] = {
            'all_results': optimization_results,
            'best_result': best_result
        }
        
        print(f"âœ… {model_name} ìµœì í™” ì™„ë£Œ: ìµœì  ì•Œê³ ë¦¬ì¦˜ = {best_result['algorithm']}")
        
        return best_result
    
    def _gradient_descent_optimization(self, objective_function, bounds):
        """ê·¸ë˜ë””ì–¸íŠ¸ ë””ì„¼íŠ¸ ìµœì í™”"""
        # ì´ˆê¸° íŒŒë¼ë¯¸í„° ì„¤ì •
        initial_params = np.array([(bounds[i][0] + bounds[i][1]) / 2 for i in range(len(bounds))])
        
        # ê²½ê³„ ì¡°ê±´ ì„¤ì •
        constraints = []
        for i, (lower, upper) in enumerate(bounds):
            constraints.append({'type': 'ineq', 'fun': lambda x, i=i, l=lower: x[i] - l})
            constraints.append({'type': 'ineq', 'fun': lambda x, i=i, u=upper: u - x[i]})
        
        result = minimize(
            objective_function,
            initial_params,
            method='SLSQP',
            bounds=bounds,
            constraints=constraints,
            options={'maxiter': 1000}
        )
        
        return {
            'parameters': result.x.tolist(),
            'value': float(result.fun),
            'iterations': int(result.nit),
            'convergence': bool(result.success)
        }
    
    def _genetic_algorithm_optimization(self, objective_function, bounds):
        """ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ìµœì í™”"""
        def objective_wrapper(params):
            return objective_function(params)
        
        result = differential_evolution(
            objective_wrapper,
            bounds,
            maxiter=1000,
            popsize=15,
            seed=42
        )
        
        return {
            'parameters': result.x.tolist(),
            'value': float(result.fun),
            'iterations': int(result.nit),
            'convergence': bool(result.success)
        }
    
    def _bayesian_optimization(self, objective_function, bounds):
        """ë² ì´ì§€ì•ˆ ìµœì í™” (ê°„ë‹¨í•œ êµ¬í˜„)"""
        # ê°„ë‹¨í•œ ëœë¤ ì„œì¹˜ë¡œ êµ¬í˜„
        best_params = None
        best_value = float('inf')
        
        for _ in range(1000):
            params = np.array([np.random.uniform(bounds[i][0], bounds[i][1]) for i in range(len(bounds))])
            value = objective_function(params)
            
            if value < best_value:
                best_value = value
                best_params = params
        
        return {
            'parameters': best_params.tolist() if best_params is not None else None,
            'value': float(best_value),
            'iterations': 1000,
            'convergence': True
        }
    
    def _particle_swarm_optimization(self, objective_function, bounds):
        """íŒŒí‹°í´ ìŠ¤ì›œ ìµœì í™” (ê°„ë‹¨í•œ êµ¬í˜„)"""
        # ê°„ë‹¨í•œ ëœë¤ ì„œì¹˜ë¡œ êµ¬í˜„
        best_params = None
        best_value = float('inf')
        
        for _ in range(1000):
            params = np.array([np.random.uniform(bounds[i][0], bounds[i][1]) for i in range(len(bounds))])
            value = objective_function(params)
            
            if value < best_value:
                best_value = value
                best_params = params
        
        return {
            'parameters': best_params.tolist() if best_params is not None else None,
            'value': float(best_value),
            'iterations': 1000,
            'convergence': True
        }
    
    def _select_best_result(self, optimization_results):
        """ìµœì  ê²°ê³¼ ì„ íƒ"""
        best_algorithm = None
        best_value = float('inf')
        
        for algo_name, result in optimization_results.items():
            if result['success'] and result['optimal_value'] < best_value:
                best_value = result['optimal_value']
                best_algorithm = algo_name
        
        if best_algorithm:
            return {
                'algorithm': best_algorithm,
                'parameters': optimization_results[best_algorithm]['optimal_parameters'],
                'value': optimization_results[best_algorithm]['optimal_value']
            }
        else:
            return {
                'algorithm': 'none',
                'parameters': None,
                'value': float('inf')
            }
    
    def benchmark_optimization(self, model_name, original_params, optimized_params, test_data):
        """ìµœì í™” ì „í›„ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹"""
        print(f"ğŸ“Š {model_name} ìµœì í™” ì „í›„ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ì¤‘...")
        
        # ì›ë³¸ ëª¨ë¸ ì„±ëŠ¥
        original_performance = self._evaluate_model_performance(original_params, test_data)
        
        # ìµœì í™”ëœ ëª¨ë¸ ì„±ëŠ¥
        optimized_performance = self._evaluate_model_performance(optimized_params, test_data)
        
        # ì„±ëŠ¥ ê°œì„  ê³„ì‚°
        improvement = {
            'accuracy_improvement': optimized_performance['accuracy'] - original_performance['accuracy'],
            'error_reduction': original_performance['error'] - optimized_performance['error'],
            'performance_gain': (optimized_performance['accuracy'] - original_performance['accuracy']) / original_performance['accuracy'] * 100
        }
        
        benchmark_results = {
            'model': model_name,
            'original_performance': original_performance,
            'optimized_performance': optimized_performance,
            'improvement': improvement
        }
        
        print(f"âœ… {model_name} ë²¤ì¹˜ë§ˆí‚¹ ì™„ë£Œ:")
        print(f"   - ì •í™•ë„ ê°œì„ : {improvement['accuracy_improvement']:.4f}")
        print(f"   - ì˜¤ë¥˜ ê°ì†Œ: {improvement['error_reduction']:.4f}")
        print(f"   - ì„±ëŠ¥ í–¥ìƒ: {improvement['performance_gain']:.2f}%")
        
        return benchmark_results
    
    def _evaluate_model_performance(self, parameters, test_data):
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ëª¨ë¸ì— íŒŒë¼ë¯¸í„°ë¥¼ ì ìš©í•˜ê³  ì„±ëŠ¥ì„ í‰ê°€
        # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
        accuracy = np.random.uniform(0.7, 0.95)
        error = np.random.uniform(0.05, 0.3)
        
        return {
            'accuracy': accuracy,
            'error': error,
            'parameters': parameters
        }
    
    def ab_testing(self, model_name, strategies):
        """A/B í…ŒìŠ¤íŒ…"""
        print(f"ğŸ§ª {model_name} A/B í…ŒìŠ¤íŒ… ì¤‘...")
        
        ab_results = {}
        
        for strategy_name, strategy_params in strategies.items():
            print(f"   ğŸ“ˆ {strategy_name} ì „ëµ í…ŒìŠ¤íŠ¸ ì¤‘...")
            
            # ì „ëµë³„ ì„±ëŠ¥ í‰ê°€
            performance = self._evaluate_strategy_performance(strategy_params)
            
            ab_results[strategy_name] = {
                'parameters': strategy_params,
                'performance': performance,
                'effectiveness': self._calculate_effectiveness(performance)
            }
            
            print(f"   âœ… {strategy_name} ì™„ë£Œ: íš¨ê³¼ì„± = {ab_results[strategy_name]['effectiveness']:.2f}")
        
        # ìµœì  ì „ëµ ì„ íƒ
        best_strategy = max(ab_results.items(), key=lambda x: x[1]['effectiveness'])
        
        print(f"âœ… {model_name} A/B í…ŒìŠ¤íŒ… ì™„ë£Œ: ìµœì  ì „ëµ = {best_strategy[0]}")
        
        return {
            'all_strategies': ab_results,
            'best_strategy': best_strategy
        }
    
    def _evaluate_strategy_performance(self, strategy_params):
        """ì „ëµ ì„±ëŠ¥ í‰ê°€"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì „ëµì— ë”°ë¥¸ ì„±ëŠ¥ì„ í‰ê°€
        # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
        return {
            'accuracy': np.random.uniform(0.6, 0.9),
            'efficiency': np.random.uniform(0.5, 0.8),
            'stability': np.random.uniform(0.7, 0.95)
        }
    
    def _calculate_effectiveness(self, performance):
        """íš¨ê³¼ì„± ê³„ì‚°"""
        return (performance['accuracy'] + performance['efficiency'] + performance['stability']) / 3
    
    def generate_optimization_report(self):
        """ìµœì í™” ë³´ê³ ì„œ ìƒì„±"""
        print("ğŸ“ ìµœì í™” ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'optimization_results': self.optimization_results,
            'performance_history': self.performance_history,
            'summary': self._generate_optimization_summary()
        }
        
        # ë³´ê³ ì„œ ì €ì¥
        results_dir = '/home/sslab/rocksdb-put-model/experiments/2025-09-12/phase-e/results'
        os.makedirs(results_dir, exist_ok=True)
        
        report_file = f"{results_dir}/advanced_optimization_report.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"âœ… ìµœì í™” ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_file}")
        
        return report
    
    def _generate_optimization_summary(self):
        """ìµœì í™” ìš”ì•½ ìƒì„±"""
        summary = {
            'total_models_optimized': len(self.optimization_results),
            'optimization_algorithms_used': list(self.optimization_algorithms.keys()),
            'best_improvements': [],
            'overall_effectiveness': 0.0
        }
        
        total_effectiveness = 0
        for model_name, results in self.optimization_results.items():
            if results['best_result']['algorithm'] != 'none':
                improvement = {
                    'model': model_name,
                    'algorithm': results['best_result']['algorithm'],
                    'improvement': results['best_result']['value']
                }
                summary['best_improvements'].append(improvement)
                total_effectiveness += results['best_result']['value']
        
        if len(summary['best_improvements']) > 0:
            summary['overall_effectiveness'] = total_effectiveness / len(summary['best_improvements'])
        
        return summary

def main():
    """Advanced Optimization Framework í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ Advanced Optimization Framework ì‹œì‘")
    print("=" * 60)
    
    # í”„ë ˆì„ì›Œí¬ ìƒì„±
    framework = AdvancedOptimizationFramework()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test_predictions = np.random.uniform(50, 100, 100)
    test_actual = np.random.uniform(50, 100, 100)
    
    # ëª¨ë¸ ì •í™•ë„ ë¶„ì„
    accuracy_analysis = framework.analyze_model_accuracy('test_model', test_predictions, test_actual)
    
    # íŒŒë¼ë¯¸í„° ìµœì í™”
    def objective_function(params):
        return np.sum(params**2) + np.random.normal(0, 0.1)
    
    parameter_bounds = [(-10, 10), (-10, 10), (-10, 10)]
    optimization_result = framework.optimize_model_parameters('test_model', objective_function, parameter_bounds)
    
    # A/B í…ŒìŠ¤íŒ…
    strategies = {
        'strategy_a': {'param1': 0.5, 'param2': 0.3},
        'strategy_b': {'param1': 0.7, 'param2': 0.5},
        'strategy_c': {'param1': 0.9, 'param2': 0.7}
    }
    
    ab_results = framework.ab_testing('test_model', strategies)
    
    # ë³´ê³ ì„œ ìƒì„±
    report = framework.generate_optimization_report()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ Advanced Optimization Framework ì™„ë£Œ!")
    print("=" * 60)

if __name__ == "__main__":
    main()
